{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data files...done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"reading data files...\",end=\"\")\n",
    "train_text = []\n",
    "train_topic = []\n",
    "test_text = []\n",
    "test_topic = []\n",
    "filename = \"HAM-Train-Test\\HAM-Train.txt\"\n",
    "file = open(filename,\"r\",encoding='utf-8')\n",
    "for line in file.readlines():\n",
    "    i = line.find(\"@\")\n",
    "    train_topic.append(line[:i])\n",
    "    train_text.append(line[i+10:].split(\" \")[:])\n",
    "filename = \"HAM-Train-Test\\HAM-Test.txt\"\n",
    "file = open(filename,\"r\",encoding='utf-8')\n",
    "for line in file.readlines():\n",
    "    i = line.find(\"@\")\n",
    "    test_topic.append(line[:i])\n",
    "    test_text.append(line[i+10:].split(\" \")[:])\n",
    "    \n",
    "classes = set(train_topic)\n",
    "\n",
    "words = set()\n",
    "for text in train_text:\n",
    "    for word in text:\n",
    "        words.add(word)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating Unigram and Bigram Models........done\n"
     ]
    }
   ],
   "source": [
    "# calculating unigram and bigram model\n",
    "print(\"calculating Unigram and Bigram Models...\",end=\"\")\n",
    "uni_dic = {}\n",
    "bi_dic = {}\n",
    "classes_prob = {}\n",
    "num_words_byTopic= {}\n",
    "for t in classes:\n",
    "    uni_dic[t]={}\n",
    "    bi_dic[t]={}\n",
    "    classes_prob[t]=0\n",
    "    num_words_byTopic[t]=0\n",
    "    \n",
    "for c in train_topic:\n",
    "    classes_prob[c]+=1\n",
    "x = 0\n",
    "for t in classes:\n",
    "    classes_prob[t]=classes_prob[t]/len(train_topic)\n",
    "    total = 0\n",
    "    for i in range(len(train_text)):\n",
    "        if train_topic[i]==t:\n",
    "            total+=len(train_text)\n",
    "    num_words_byTopic[t] = total\n",
    "    x+=1\n",
    "num=0\n",
    "for i in range(len(train_text)):\n",
    "    data = train_text[i]\n",
    "    for j in range(len(data)-1):\n",
    "        uni_dic[train_topic[i]][data[j]]=0\n",
    "        bi_dic[train_topic[i]][data[j],data[j+1]]=0\n",
    "    uni_dic[train_topic[i]][data[j+1]]=0\n",
    "    num+=1\n",
    "    if num == 3000:\n",
    "        print(\".\",end=\"\")\n",
    "        num=0\n",
    "for i in range(len(train_text)):\n",
    "    data = train_text[i]\n",
    "    for j in range(len(data)-1):\n",
    "        uni_dic[train_topic[i]][data[j]]+=1\n",
    "        bi_dic[train_topic[i]][data[j],data[j+1]]+=1\n",
    "    uni_dic[train_topic[i]][data[j+1]]+=1\n",
    "    num+=1\n",
    "    if num == 3000:\n",
    "        print(\".\",end=\"\")\n",
    "        num=0\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifying test set...........done\n"
     ]
    }
   ],
   "source": [
    "# calculating test predictions using unigram and bigram\n",
    "uni_pred = []\n",
    "bi_pred = []\n",
    "lambda1 = 0.2\n",
    "lambda2 = 0.8\n",
    "print(\"classifying test set...\",end=\"\")\n",
    "test_num = 0\n",
    "for i in range(len(test_text)):\n",
    "    test = test_text[i]\n",
    "    this_test_prob_uni = {}\n",
    "    this_test_prob_bi = {}\n",
    "    for x in classes:\n",
    "        this_test_prob_uni[x] = 0 \n",
    "        this_test_prob_bi[x] = 0 \n",
    "    for j in range(len(test)-1):\n",
    "        word = test[j]\n",
    "        word2 = (test[j],test[j+1])\n",
    "        for topic in classes:\n",
    "            topic_prob_uni = 0\n",
    "            topic_prob_bi = 0\n",
    "            \n",
    "            prob1 = uni_dic[topic].get(word)\n",
    "            if prob1 == None:\n",
    "                prob1 = 0.000001\n",
    "            prob1 = np.log(prob1/num_words_byTopic[topic])\n",
    "            \n",
    "            prob2 = bi_dic[topic].get(word2)\n",
    "            prob22 = uni_dic[topic].get(word2[1])\n",
    "            prob21 = uni_dic[topic].get(word2[0])\n",
    "            if prob2 == None:\n",
    "                prob2 = 0.000000001\n",
    "                if prob22 == None:\n",
    "                    prob22 = 0.000001\n",
    "                prob2 = lambda1*(prob2) + lambda2*(prob22/num_words_byTopic[topic])\n",
    "            else:\n",
    "                prob2 = prob2/prob21        \n",
    "            prob2 = np.log(prob2)\n",
    "            this_test_prob_uni[topic] += prob1\n",
    "            this_test_prob_bi[topic] += prob2\n",
    "    this_test_prob_uni[topic] += np.log(classes_prob[topic])\n",
    "    this_test_prob_bi[topic] += np.log(classes_prob[topic])\n",
    "    uni_pred.append(this_test_prob_uni.copy())\n",
    "    bi_pred.append(this_test_prob_bi.copy())   \n",
    "    test_num+=1\n",
    "    if test_num == 100:\n",
    "        print(\".\",end=\"\")\n",
    "        test_num=0\n",
    "print(\"done\")\n",
    "index = 0\n",
    "hit = 0\n",
    "topic = []\n",
    "for i in classes:\n",
    "    topic.append(i)\n",
    "for x in uni_pred:\n",
    "    temp = []\n",
    "    for t in topic:\n",
    "        temp.append(x[t])\n",
    "    if topic[np.argmax(temp)]==test_topic[index]:\n",
    "        hit += 1\n",
    "    index += 1\n",
    "\n",
    "hit2 = 0\n",
    "index = 0\n",
    "for x in bi_pred:\n",
    "    temp = []\n",
    "    for t in topic:\n",
    "        temp.append(x[t])\n",
    "    if topic[np.argmax(temp)]==test_topic[index]:\n",
    "        hit2 += 1\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating percition and recall\n",
    "topic = []\n",
    "for i in classes:\n",
    "    topic.append(i)\n",
    "\n",
    "topic_test = []\n",
    "for t in test_topic:\n",
    "    topic_test.append(topic.index(t))\n",
    "pred_uni = []\n",
    "for pred in uni_pred:\n",
    "    temp = []\n",
    "    for t in topic:\n",
    "        temp.append(pred[t])\n",
    "    pred_uni.append(np.argmax(temp))\n",
    "pred_bi = []\n",
    "for pred in bi_pred:\n",
    "    temp = []\n",
    "    for t in topic:\n",
    "        temp.append(pred[t])\n",
    "    pred_bi.append(np.argmax(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS:\n",
      "______________________________\n",
      "unigram true predictions: 693\\860\n",
      "precision(UNIgram):\n",
      "   سیاسی : 0.895\n",
      "   اقتصاد : 0.978\n",
      "   اجتماعی : 0.531\n",
      "   ورزش : 0.995\n",
      "   ادب و هنر : 0.797\n",
      "recall(UNIgram):\n",
      "   سیاسی : 0.685\n",
      "   اقتصاد : 0.658\n",
      "   اجتماعی : 0.926\n",
      "   ورزش : 0.925\n",
      "   ادب و هنر : 0.948\n",
      "F1_score(UNIgram):\n",
      "   سیاسی : 0.776\n",
      "   اقتصاد : 0.787\n",
      "   اجتماعی : 0.675\n",
      "   ورزش : 0.959\n",
      "   ادب و هنر : 0.866\n",
      "______________________________\n",
      "bigram true predictions: 673\\860\n",
      "precision(BIgram):\n",
      "   سیاسی : 0.916\n",
      "   اقتصاد : 0.883\n",
      "   اجتماعی : 0.926\n",
      "   ورزش : 0.976\n",
      "   ادب و هنر : 0.281\n",
      "recall(BIgram):\n",
      "   سیاسی : 0.77\n",
      "   اقتصاد : 0.900\n",
      "   اجتماعی : 0.386\n",
      "   ورزش : 0.929\n",
      "   ادب و هنر : 0.931\n",
      "F1_score(BIgram):\n",
      "   سیاسی : 0.836\n",
      "   اقتصاد : 0.892\n",
      "   اجتماعی : 0.545\n",
      "   ورزش : 0.952\n",
      "   ادب و هنر : 0.432\n"
     ]
    }
   ],
   "source": [
    "uni_result_MAT = []\n",
    "for i in range(len(topic)):\n",
    "    uni_result_MAT.append([])\n",
    "    for j in range(len(topic)):\n",
    "        uni_result_MAT[i].append(0)\n",
    "for i in range(len(pred_uni)):\n",
    "    uni_result_MAT[topic_test[i]][pred_uni[i]]+=1\n",
    "\n",
    "bi_result_MAT = []\n",
    "for i in range(len(topic)):\n",
    "    bi_result_MAT.append([])\n",
    "    for j in range(len(topic)):\n",
    "        bi_result_MAT[i].append(0)\n",
    "for i in range(len(pred_uni)):\n",
    "    bi_result_MAT[topic_test[i]][pred_bi[i]]+=1\n",
    "\n",
    "precision_uni = []\n",
    "precision_bi = []\n",
    "recall_uni = []\n",
    "recall_bi = []\n",
    "#percision\n",
    "for t in range(len(topic)):\n",
    "    tu = uni_result_MAT[t][t]\n",
    "    fu = 0\n",
    "    tb = bi_result_MAT[t][t]\n",
    "    fb = 0\n",
    "    for pu in uni_result_MAT:\n",
    "        fu+=pu[t]\n",
    "    for pb in bi_result_MAT:\n",
    "        fb+=pb[t]\n",
    "    precision_uni.append(tu/fu)\n",
    "    precision_bi.append(tb/fb)\n",
    "#recall\n",
    "for t in range(len(topic)):\n",
    "    tu = uni_result_MAT[t][t]\n",
    "    fu = sum(uni_result_MAT[t])\n",
    "    tb = bi_result_MAT[t][t]\n",
    "    fb = sum(bi_result_MAT[t])\n",
    "    recall_uni.append(tu/fu)\n",
    "    recall_bi.append(tb/fb)\n",
    "f1_uni = []\n",
    "f1_bi = []\n",
    "for i in range(len(topic)):\n",
    "    f1_uni.append((2*precision_uni[i]*recall_uni[i])/(precision_uni[i]+recall_uni[i]))\n",
    "    f1_bi.append((2*precision_bi[i]*recall_bi[i])/(precision_bi[i]+recall_bi[i]))\n",
    "print(\"RESULTS:\")\n",
    "print(\"______________________________\")\n",
    "print(\"unigram true predictions: \"+str(hit)+\"\\\\\"+str(len(test_text)))\n",
    "print(\"precision(UNIgram):\")\n",
    "for i in range(len(topic)):\n",
    "    print(\"   \"+topic[i]+\" : \"+str(precision_uni[i])[:5])\n",
    "print(\"recall(UNIgram):\")\n",
    "for i in range(len(topic)):\n",
    "    print(\"   \"+topic[i]+\" : \"+str(recall_uni[i])[:5])\n",
    "print(\"F1_score(UNIgram):\")\n",
    "for i in range(len(topic)):\n",
    "    print(\"   \"+topic[i]+\" : \"+str(f1_uni[i])[:5])\n",
    "print(\"______________________________\")\n",
    "print(\"bigram true predictions: \"+str(hit2)+\"\\\\\"+str(len(test_text)))\n",
    "print(\"precision(BIgram):\")\n",
    "for i in range(len(topic)):\n",
    "    print(\"   \"+topic[i]+\" : \"+str(precision_bi[i])[:5])\n",
    "print(\"recall(BIgram):\")\n",
    "for i in range(len(topic)):\n",
    "    print(\"   \"+topic[i]+\" : \"+str(recall_bi[i])[:5])\n",
    "print(\"F1_score(BIgram):\")\n",
    "for i in range(len(topic)):\n",
    "    print(\"   \"+topic[i]+\" : \"+str(f1_bi[i])[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8682170542635659, 0.7909604519774013, 0.7740112994350283, 0.9612756264236901, 0.6801801801801802]\n"
     ]
    }
   ],
   "source": [
    "print(f1_uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-7ad627ea509b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mtemp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtest_topic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mcp\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mz\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "\n",
    "    test = test_text[i]\n",
    "    this_test_prob_uni = []\n",
    "    this_test_prob_bi = []\n",
    "    for topic in classes:\n",
    "        this_topic_prob_uni = 0\n",
    "        this_topic_prob_bi = 0\n",
    "        for j in range(len(test)-1):\n",
    "            word = test[j]\n",
    "            word2 = (test[j],test[j+1])\n",
    "            prob = uni_dic[topic].get(word)\n",
    "            prob2 = bi_dic[topic].get(word2)\n",
    "            if prob == None:\n",
    "                prob = 0.000001\n",
    "            if prob2 == None:\n",
    "                prob2 = 0.000001\n",
    "            prob = prob/num_words_byTopic[topic]\n",
    "            numenator = test.count(word2[0]) + 1\n",
    "            param1 = uni_dic[topic].get(word2[1])\n",
    "            if param1 == None:\n",
    "                param1 = 0.000001\n",
    "            param2 = (prob2/numenator)\n",
    "            prob2 = lambda1*param1 + lambda2*param2\n",
    "            this_topic_prob_uni+=np.log(prob)\n",
    "            this_topic_prob_bi+=np.log(prob2)\n",
    "        this_topic_prob_uni+=np.log(classes_prob[topic])\n",
    "        this_topic_prob_bi+=np.log(classes_prob[topic])\n",
    "        this_test_prob_uni.append([topic,this_topic_prob_uni])\n",
    "        this_test_prob_bi.append([topic,this_topic_prob_bi])\n",
    "    uni_pred.append(this_test_prob_uni)\n",
    "    bi_pred.append(this_test_prob_bi)\n",
    "z=0\n",
    "cp = 0\n",
    "for x in uni_pred:\n",
    "    temp = []\n",
    "    for p in x:\n",
    "        temp.append(p[1])\n",
    "    if (test_topic[z]==x[np.argmax(temp)][0]) :\n",
    "        cp+=1\n",
    "    z+=1\n",
    "cp2 = 0\n",
    "z=0\n",
    "print(cp,len(uni_pred))\n",
    "for x in bi_pred:\n",
    "    temp = []\n",
    "    for p in x:\n",
    "        temp.append(p[1])\n",
    "    if (test_topic[z]==x[np.argmax(temp)][0]) :\n",
    "        cp2+=1\n",
    "    z+=1\n",
    "print(cp2,len(bi_pred))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
